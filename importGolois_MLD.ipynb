{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tintamaria95/CocoriGo/blob/main/importGolois_MLD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks7AjhAto2dV"
      },
      "outputs": [],
      "source": [
        "!wget https://www.lamsade.dauphine.fr/~cazenave/project2022.zip\n",
        "!unzip project2022.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNxDy5hTfHs_",
        "outputId": "aa2c1760-7688-4de5-f16a-2af7a0f1f654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getValidation\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "tcmalloc: large alloc 2400002048 bytes == 0x5792c000 @  0x7f0a68b62887 0x7f09ee6d30d9 0x7f09ee6d885f 0x7f09ee6ed06f 0x58f6e4 0x5105e2 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82 0x64dd2e 0x7f0a6875dc87 0x5b636a\n",
            "nbPositionsSGF = 29425326\n",
            "nbPositionsSGF = 29425326\n",
            "loading validation.data\n",
            "2022-11-10 14:58:18.603762: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " board (InputLayer)             [(None, 19, 19, 31)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 19, 19, 32)   1024        ['board[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 19, 19, 32)   25632       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 19, 19, 32)   1056        ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 19, 19, 32)   0           ['conv2d_1[0][0]',               \n",
            "                                                                  'conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 19, 19, 32)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 19, 19, 32)   25632       ['re_lu[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 19, 19, 32)   1056        ['re_lu[0][0]']                  \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 19, 19, 32)   0           ['conv2d_3[0][0]',               \n",
            "                                                                  'conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 19, 19, 32)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 19, 19, 32)   25632       ['re_lu_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 19, 19, 32)   1056        ['re_lu_1[0][0]']                \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 19, 19, 32)   0           ['conv2d_5[0][0]',               \n",
            "                                                                  'conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 19, 19, 32)   0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 19, 19, 1)    32          ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 19, 19, 1)    32          ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 361)          0           ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 361)          0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 50)           18100       ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " policy (Activation)            (None, 361)          0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " value (Dense)                  (None, 1)            51          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 99,303\n",
            "Trainable params: 99,303\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "epoch 1\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "2022-11-10 14:58:20.517966: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n",
            "79/79 [==============================] - 5s 18ms/step - loss: 6.5923 - policy_loss: 5.8898 - value_loss: 0.6931 - policy_categorical_accuracy: 0.0011 - value_mse: 0.1215\n",
            "epoch 2\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "2022-11-10 14:58:27.396786: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 6.5914 - policy_loss: 5.8889 - value_loss: 0.6931 - policy_categorical_accuracy: 0.0018 - value_mse: 0.1194\n",
            "epoch 3\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "2022-11-10 14:58:31.834860: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 6.5910 - policy_loss: 5.8889 - value_loss: 0.6927 - policy_categorical_accuracy: 0.0011 - value_mse: 0.1203\n",
            "epoch 4\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "2022-11-10 14:58:35.058828: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 6.5908 - policy_loss: 5.8889 - value_loss: 0.6925 - policy_categorical_accuracy: 0.0016 - value_mse: 0.1205\n",
            "epoch 5\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "2022-11-10 14:58:38.384347: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 447640000 exceeds 10% of free system memory.\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 6.5907 - policy_loss: 5.8889 - value_loss: 0.6924 - policy_categorical_accuracy: 0.0019 - value_mse: 0.1192\n",
            "epoch 6\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 6.5892 - policy_loss: 5.8889 - value_loss: 0.6909 - policy_categorical_accuracy: 0.0019 - value_mse: 0.1169\n",
            "epoch 7\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 6.5884 - policy_loss: 5.8889 - value_loss: 0.6902 - policy_categorical_accuracy: 0.0011 - value_mse: 0.1187\n",
            "epoch 8\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 6.5880 - policy_loss: 5.8889 - value_loss: 0.6897 - policy_categorical_accuracy: 0.0011 - value_mse: 0.1181\n",
            "epoch 9\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 6.5873 - policy_loss: 5.8889 - value_loss: 0.6891 - policy_categorical_accuracy: 0.0016 - value_mse: 0.1170\n",
            "epoch 10\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 6.5864 - policy_loss: 5.8888 - value_loss: 0.6882 - policy_categorical_accuracy: 0.0020 - value_mse: 0.1166\n",
            "epoch 11\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 6.5858 - policy_loss: 5.8889 - value_loss: 0.6876 - policy_categorical_accuracy: 0.0023 - value_mse: 0.1184\n",
            "epoch 12\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 6.5855 - policy_loss: 5.8887 - value_loss: 0.6875 - policy_categorical_accuracy: 0.0028 - value_mse: 0.1175\n",
            "epoch 13\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 6.5851 - policy_loss: 5.8883 - value_loss: 0.6875 - policy_categorical_accuracy: 0.0039 - value_mse: 0.1163\n",
            "epoch 14\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 6.5406 - policy_loss: 5.8431 - value_loss: 0.6882 - policy_categorical_accuracy: 0.0092 - value_mse: 0.1152\n",
            "epoch 15\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 16ms/step - loss: 5.5634 - policy_loss: 4.8624 - value_loss: 0.6917 - policy_categorical_accuracy: 0.0537 - value_mse: 0.1196\n",
            "epoch 16\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 4.7239 - policy_loss: 4.0247 - value_loss: 0.6898 - policy_categorical_accuracy: 0.1538 - value_mse: 0.1166\n",
            "epoch 17\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 4.5915 - policy_loss: 3.8926 - value_loss: 0.6895 - policy_categorical_accuracy: 0.1736 - value_mse: 0.1166\n",
            "epoch 18\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 4.4295 - policy_loss: 3.7304 - value_loss: 0.6897 - policy_categorical_accuracy: 0.1949 - value_mse: 0.1193\n",
            "epoch 19\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 4.2638 - policy_loss: 3.5657 - value_loss: 0.6887 - policy_categorical_accuracy: 0.2192 - value_mse: 0.1153\n",
            "epoch 20\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 4.1538 - policy_loss: 3.4555 - value_loss: 0.6890 - policy_categorical_accuracy: 0.2430 - value_mse: 0.1185\n",
            "r.shape = (10000, 19, 19, 31)\n",
            "nbExamples = 10000\n",
            "val = [4.1131157875061035, 3.4145984649658203, 0.6891785860061646, 0.2483000010251999, 0.11806979030370712]\n"
          ]
        }
      ],
      "source": [
        "!python golois.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Réentraînement de modèle"
      ],
      "metadata": {
        "id": "YspjcRt5pFvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "import golois\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "planes = 31\n",
        "moves = 361\n",
        "N = 10000\n",
        "batch = 128\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "input_data = input_data.astype ('float32')\n",
        "policy = np.random.randint(moves, size=(N,))\n",
        "policy = keras.utils.to_categorical (policy)\n",
        "value = np.random.randint(2, size=(N,))\n",
        "value = value.astype ('float32')\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "end = end.astype ('float32')\n",
        "groups = np.zeros((N, 19, 19, 1))\n",
        "groups = groups.astype ('float32')\n",
        "golois.getValidation (input_data, policy, value, end)\n",
        "\n",
        "# Load models\n",
        "model_name = \"model_resnet_SGD_lr5_10-3.h5\"\n",
        "model = keras.models.load_model(model_name)\n",
        "m_names = model.metrics_names\n",
        "\n",
        "for i in range (1, epochs + 1):\n",
        "    print ('epoch ' + str (i))\n",
        "    golois.getBatch (input_data, policy, value, end, groups, i * N)\n",
        "    history = model.fit(input_data,\n",
        "                        {'policy': policy, 'value': value}, \n",
        "                        epochs=1, batch_size=batch)\n",
        "    if (i % 20 == 0):\n",
        "        gc.collect ()\n",
        "        golois.getValidation (input_data, policy, value, end)\n",
        "        val = model.evaluate (input_data,\n",
        "                              [policy, value], verbose = 0, batch_size=batch)\n",
        "        print (\"val =\", val)\n",
        "        model.save (model_name)\n",
        "\n",
        "print(\"\")\n",
        "print(\"*******************\")\n",
        "print(model_name)\n",
        "for i, metric in enumerate(m_names):\n",
        "  print(metric, \":\", val[i])\n",
        "#display(keras.utils.plot_model(model, str(model_name + \".png\"), show_shapes=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5o27FgRpKtX",
        "outputId": "59b8244e-3a46-47c7-89be-e95cc835d26b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\n",
            "79/79 [==============================] - 3s 20ms/step - loss: 4.0841 - policy_loss: 3.3855 - value_loss: 0.6893 - policy_categorical_accuracy: 0.2561 - value_mse: 0.1196\n",
            "epoch 2\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.9953 - policy_loss: 3.2966 - value_loss: 0.6894 - policy_categorical_accuracy: 0.2616 - value_mse: 0.1175\n",
            "epoch 3\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.9766 - policy_loss: 3.2786 - value_loss: 0.6887 - policy_categorical_accuracy: 0.2650 - value_mse: 0.1183\n",
            "epoch 4\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.8664 - policy_loss: 3.1669 - value_loss: 0.6902 - policy_categorical_accuracy: 0.2858 - value_mse: 0.1193\n",
            "epoch 5\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 3.8512 - policy_loss: 3.1513 - value_loss: 0.6906 - policy_categorical_accuracy: 0.2908 - value_mse: 0.1182\n",
            "epoch 6\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.8384 - policy_loss: 3.1392 - value_loss: 0.6900 - policy_categorical_accuracy: 0.2923 - value_mse: 0.1164\n",
            "epoch 7\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.8204 - policy_loss: 3.1214 - value_loss: 0.6897 - policy_categorical_accuracy: 0.2874 - value_mse: 0.1185\n",
            "epoch 8\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 3.7797 - policy_loss: 3.0807 - value_loss: 0.6898 - policy_categorical_accuracy: 0.2914 - value_mse: 0.1182\n",
            "epoch 9\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.7615 - policy_loss: 3.0628 - value_loss: 0.6894 - policy_categorical_accuracy: 0.2933 - value_mse: 0.1172\n",
            "epoch 10\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.7587 - policy_loss: 3.0602 - value_loss: 0.6893 - policy_categorical_accuracy: 0.2953 - value_mse: 0.1171\n",
            "epoch 11\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.7210 - policy_loss: 3.0224 - value_loss: 0.6894 - policy_categorical_accuracy: 0.3075 - value_mse: 0.1193\n",
            "epoch 12\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.7066 - policy_loss: 3.0087 - value_loss: 0.6887 - policy_categorical_accuracy: 0.3030 - value_mse: 0.1181\n",
            "epoch 13\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 3.6752 - policy_loss: 2.9764 - value_loss: 0.6896 - policy_categorical_accuracy: 0.3133 - value_mse: 0.1173\n",
            "epoch 14\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.6994 - policy_loss: 3.0000 - value_loss: 0.6902 - policy_categorical_accuracy: 0.3040 - value_mse: 0.1162\n",
            "epoch 15\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.7328 - policy_loss: 3.0336 - value_loss: 0.6901 - policy_categorical_accuracy: 0.2987 - value_mse: 0.1188\n",
            "epoch 16\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.6770 - policy_loss: 2.9778 - value_loss: 0.6901 - policy_categorical_accuracy: 0.3159 - value_mse: 0.1168\n",
            "epoch 17\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.7081 - policy_loss: 3.0105 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3022 - value_mse: 0.1161\n",
            "epoch 18\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.6696 - policy_loss: 2.9708 - value_loss: 0.6897 - policy_categorical_accuracy: 0.3079 - value_mse: 0.1193\n",
            "epoch 19\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.6721 - policy_loss: 2.9754 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3100 - value_mse: 0.1147\n",
            "epoch 20\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.6216 - policy_loss: 2.9239 - value_loss: 0.6887 - policy_categorical_accuracy: 0.3132 - value_mse: 0.1184\n",
            "val = [3.6549952030181885, 2.9572651386260986, 0.6886540055274963, 0.31310001015663147, 0.11780643463134766]\n",
            "epoch 21\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.6318 - policy_loss: 2.9354 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3130 - value_mse: 0.1163\n",
            "epoch 22\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.6584 - policy_loss: 2.9605 - value_loss: 0.6889 - policy_categorical_accuracy: 0.3119 - value_mse: 0.1182\n",
            "epoch 23\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.6334 - policy_loss: 2.9349 - value_loss: 0.6895 - policy_categorical_accuracy: 0.3132 - value_mse: 0.1182\n",
            "epoch 24\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.6304 - policy_loss: 2.9333 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3240 - value_mse: 0.1176\n",
            "epoch 25\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.6330 - policy_loss: 2.9354 - value_loss: 0.6886 - policy_categorical_accuracy: 0.3161 - value_mse: 0.1167\n",
            "epoch 26\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.6410 - policy_loss: 2.9440 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3102 - value_mse: 0.1158\n",
            "epoch 27\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5845 - policy_loss: 2.8850 - value_loss: 0.6905 - policy_categorical_accuracy: 0.3209 - value_mse: 0.1196\n",
            "epoch 28\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5719 - policy_loss: 2.8740 - value_loss: 0.6890 - policy_categorical_accuracy: 0.3276 - value_mse: 0.1171\n",
            "epoch 29\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.5868 - policy_loss: 2.8885 - value_loss: 0.6894 - policy_categorical_accuracy: 0.3270 - value_mse: 0.1170\n",
            "epoch 30\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.5320 - policy_loss: 2.8355 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3220 - value_mse: 0.1170\n",
            "epoch 31\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5950 - policy_loss: 2.8984 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3144 - value_mse: 0.1157\n",
            "epoch 32\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5736 - policy_loss: 2.8748 - value_loss: 0.6899 - policy_categorical_accuracy: 0.3236 - value_mse: 0.1169\n",
            "epoch 33\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5730 - policy_loss: 2.8751 - value_loss: 0.6891 - policy_categorical_accuracy: 0.3191 - value_mse: 0.1165\n",
            "epoch 34\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5800 - policy_loss: 2.8814 - value_loss: 0.6897 - policy_categorical_accuracy: 0.3253 - value_mse: 0.1182\n",
            "epoch 35\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.5455 - policy_loss: 2.8474 - value_loss: 0.6893 - policy_categorical_accuracy: 0.3329 - value_mse: 0.1163\n",
            "epoch 36\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.5599 - policy_loss: 2.8638 - value_loss: 0.6872 - policy_categorical_accuracy: 0.3234 - value_mse: 0.1175\n",
            "epoch 37\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5572 - policy_loss: 2.8600 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3293 - value_mse: 0.1179\n",
            "epoch 38\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.5764 - policy_loss: 2.8794 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3231 - value_mse: 0.1180\n",
            "epoch 39\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5673 - policy_loss: 2.8694 - value_loss: 0.6891 - policy_categorical_accuracy: 0.3213 - value_mse: 0.1174\n",
            "epoch 40\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.5725 - policy_loss: 2.8736 - value_loss: 0.6901 - policy_categorical_accuracy: 0.3270 - value_mse: 0.1156\n",
            "val = [3.5048985481262207, 2.805100679397583, 0.6910142302513123, 0.3346000015735626, 0.11896713823080063]\n",
            "epoch 41\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5490 - policy_loss: 2.8513 - value_loss: 0.6889 - policy_categorical_accuracy: 0.3272 - value_mse: 0.1168\n",
            "epoch 42\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5328 - policy_loss: 2.8356 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3277 - value_mse: 0.1187\n",
            "epoch 43\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.4853 - policy_loss: 2.7872 - value_loss: 0.6893 - policy_categorical_accuracy: 0.3389 - value_mse: 0.1172\n",
            "epoch 44\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4866 - policy_loss: 2.7886 - value_loss: 0.6892 - policy_categorical_accuracy: 0.3354 - value_mse: 0.1173\n",
            "epoch 45\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.5246 - policy_loss: 2.8274 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3312 - value_mse: 0.1168\n",
            "epoch 46\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.5145 - policy_loss: 2.8164 - value_loss: 0.6894 - policy_categorical_accuracy: 0.3302 - value_mse: 0.1175\n",
            "epoch 47\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4996 - policy_loss: 2.8029 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3340 - value_mse: 0.1185\n",
            "epoch 48\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.5247 - policy_loss: 2.8277 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3304 - value_mse: 0.1186\n",
            "epoch 49\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5079 - policy_loss: 2.8096 - value_loss: 0.6896 - policy_categorical_accuracy: 0.3331 - value_mse: 0.1190\n",
            "epoch 50\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4840 - policy_loss: 2.7863 - value_loss: 0.6890 - policy_categorical_accuracy: 0.3389 - value_mse: 0.1186\n",
            "epoch 51\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.5129 - policy_loss: 2.8159 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3336 - value_mse: 0.1190\n",
            "epoch 52\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.5140 - policy_loss: 2.8171 - value_loss: 0.6882 - policy_categorical_accuracy: 0.3282 - value_mse: 0.1151\n",
            "epoch 53\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 3.5374 - policy_loss: 2.8414 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3228 - value_mse: 0.1165\n",
            "epoch 54\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 3.5032 - policy_loss: 2.8061 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3402 - value_mse: 0.1167\n",
            "epoch 55\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.5164 - policy_loss: 2.8208 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3348 - value_mse: 0.1166\n",
            "epoch 56\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4989 - policy_loss: 2.8019 - value_loss: 0.6884 - policy_categorical_accuracy: 0.3358 - value_mse: 0.1179\n",
            "epoch 57\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4939 - policy_loss: 2.7973 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3344 - value_mse: 0.1189\n",
            "epoch 58\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.5007 - policy_loss: 2.8035 - value_loss: 0.6887 - policy_categorical_accuracy: 0.3303 - value_mse: 0.1178\n",
            "epoch 59\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.4724 - policy_loss: 2.7765 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3416 - value_mse: 0.1172\n",
            "epoch 60\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4852 - policy_loss: 2.7886 - value_loss: 0.6881 - policy_categorical_accuracy: 0.3367 - value_mse: 0.1173\n",
            "val = [3.459401845932007, 2.7630505561828613, 0.68782639503479, 0.3433000147342682, 0.11739908158779144]\n",
            "epoch 61\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4686 - policy_loss: 2.7715 - value_loss: 0.6886 - policy_categorical_accuracy: 0.3421 - value_mse: 0.1178\n",
            "epoch 62\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4875 - policy_loss: 2.7902 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3361 - value_mse: 0.1178\n",
            "epoch 63\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4548 - policy_loss: 2.7586 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3395 - value_mse: 0.1155\n",
            "epoch 64\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4793 - policy_loss: 2.7823 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3365 - value_mse: 0.1177\n",
            "epoch 65\n",
            "79/79 [==============================] - 2s 21ms/step - loss: 3.4815 - policy_loss: 2.7841 - value_loss: 0.6889 - policy_categorical_accuracy: 0.3329 - value_mse: 0.1184\n",
            "epoch 66\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.4747 - policy_loss: 2.7793 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3383 - value_mse: 0.1160\n",
            "epoch 67\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4790 - policy_loss: 2.7832 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3341 - value_mse: 0.1153\n",
            "epoch 68\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4750 - policy_loss: 2.7788 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3357 - value_mse: 0.1169\n",
            "epoch 69\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 3.4884 - policy_loss: 2.7924 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3369 - value_mse: 0.1172\n",
            "epoch 70\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4777 - policy_loss: 2.7825 - value_loss: 0.6868 - policy_categorical_accuracy: 0.3380 - value_mse: 0.1167\n",
            "epoch 71\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4932 - policy_loss: 2.7965 - value_loss: 0.6883 - policy_categorical_accuracy: 0.3334 - value_mse: 0.1175\n",
            "epoch 72\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4667 - policy_loss: 2.7694 - value_loss: 0.6889 - policy_categorical_accuracy: 0.3389 - value_mse: 0.1175\n",
            "epoch 73\n",
            "79/79 [==============================] - 2s 20ms/step - loss: 3.4672 - policy_loss: 2.7715 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3362 - value_mse: 0.1150\n",
            "epoch 74\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4397 - policy_loss: 2.7434 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3379 - value_mse: 0.1149\n",
            "epoch 75\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4503 - policy_loss: 2.7545 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3402 - value_mse: 0.1161\n",
            "epoch 76\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4718 - policy_loss: 2.7755 - value_loss: 0.6879 - policy_categorical_accuracy: 0.3417 - value_mse: 0.1154\n",
            "epoch 77\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4876 - policy_loss: 2.7916 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3266 - value_mse: 0.1167\n",
            "epoch 78\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4309 - policy_loss: 2.7329 - value_loss: 0.6897 - policy_categorical_accuracy: 0.3455 - value_mse: 0.1178\n",
            "epoch 79\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4801 - policy_loss: 2.7848 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3399 - value_mse: 0.1161\n",
            "epoch 80\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4596 - policy_loss: 2.7637 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3418 - value_mse: 0.1172\n",
            "val = [3.4325480461120605, 2.736253499984741, 0.6880298256874084, 0.34850001335144043, 0.117499440908432]\n",
            "epoch 81\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4549 - policy_loss: 2.7593 - value_loss: 0.6873 - policy_categorical_accuracy: 0.3378 - value_mse: 0.1157\n",
            "epoch 82\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.4888 - policy_loss: 2.7929 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3340 - value_mse: 0.1157\n",
            "epoch 83\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4633 - policy_loss: 2.7671 - value_loss: 0.6880 - policy_categorical_accuracy: 0.3357 - value_mse: 0.1172\n",
            "epoch 84\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4491 - policy_loss: 2.7531 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3366 - value_mse: 0.1157\n",
            "epoch 85\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4290 - policy_loss: 2.7314 - value_loss: 0.6894 - policy_categorical_accuracy: 0.3476 - value_mse: 0.1168\n",
            "epoch 86\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4385 - policy_loss: 2.7428 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3463 - value_mse: 0.1172\n",
            "epoch 87\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4353 - policy_loss: 2.7397 - value_loss: 0.6874 - policy_categorical_accuracy: 0.3445 - value_mse: 0.1175\n",
            "epoch 88\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4129 - policy_loss: 2.7177 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3412 - value_mse: 0.1179\n",
            "epoch 89\n",
            "79/79 [==============================] - 2s 19ms/step - loss: 3.4819 - policy_loss: 2.7869 - value_loss: 0.6868 - policy_categorical_accuracy: 0.3352 - value_mse: 0.1169\n",
            "epoch 90\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.4266 - policy_loss: 2.7319 - value_loss: 0.6865 - policy_categorical_accuracy: 0.3489 - value_mse: 0.1180\n",
            "epoch 91\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 3.4815 - policy_loss: 2.7856 - value_loss: 0.6878 - policy_categorical_accuracy: 0.3336 - value_mse: 0.1176\n",
            "epoch 92\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.4696 - policy_loss: 2.7726 - value_loss: 0.6888 - policy_categorical_accuracy: 0.3368 - value_mse: 0.1169\n",
            "epoch 93\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.4126 - policy_loss: 2.7160 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3501 - value_mse: 0.1172\n",
            "epoch 94\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 3.4503 - policy_loss: 2.7552 - value_loss: 0.6870 - policy_categorical_accuracy: 0.3357 - value_mse: 0.1175\n",
            "epoch 95\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 3.4403 - policy_loss: 2.7433 - value_loss: 0.6889 - policy_categorical_accuracy: 0.3395 - value_mse: 0.1175\n",
            "epoch 96\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.4377 - policy_loss: 2.7420 - value_loss: 0.6876 - policy_categorical_accuracy: 0.3397 - value_mse: 0.1168\n",
            "epoch 97\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 3.4098 - policy_loss: 2.7132 - value_loss: 0.6885 - policy_categorical_accuracy: 0.3475 - value_mse: 0.1176\n",
            "epoch 98\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 3.4460 - policy_loss: 2.7503 - value_loss: 0.6877 - policy_categorical_accuracy: 0.3393 - value_mse: 0.1180\n",
            "epoch 99\n",
            "79/79 [==============================] - 1s 18ms/step - loss: 3.4315 - policy_loss: 2.7364 - value_loss: 0.6871 - policy_categorical_accuracy: 0.3431 - value_mse: 0.1170\n",
            "epoch 100\n",
            "79/79 [==============================] - 1s 19ms/step - loss: 3.4388 - policy_loss: 2.7433 - value_loss: 0.6875 - policy_categorical_accuracy: 0.3480 - value_mse: 0.1171\n",
            "val = [3.402923107147217, 2.7068774700164795, 0.6880325078964233, 0.3497999906539917, 0.11750150471925735]\n",
            "\n",
            "*******************\n",
            "model_resnet_SGD_lr5_10-3.h5\n",
            "loss : 3.402923107147217\n",
            "policy_loss : 2.7068774700164795\n",
            "value_loss : 0.6880325078964233\n",
            "policy_categorical_accuracy : 0.3497999906539917\n",
            "value_mse : 0.11750150471925735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparaison de modèles"
      ],
      "metadata": {
        "id": "MPAW-UCStMkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import gc\n",
        "import os\n",
        "\n",
        "import golois\n",
        "\n",
        "planes = 31\n",
        "moves = 361\n",
        "N = 10000\n",
        "batch = 128\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "input_data = input_data.astype ('float32')\n",
        "policy = np.random.randint(moves, size=(N,))\n",
        "policy = keras.utils.to_categorical (policy)\n",
        "value = np.random.randint(2, size=(N,))\n",
        "value = value.astype ('float32')\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "end = end.astype ('float32')\n",
        "groups = np.zeros((N, 19, 19, 1))\n",
        "groups = groups.astype ('float32')\n",
        "print (\"getValidation\", flush = True)\n",
        "golois.getValidation (input_data, policy, value, end)\n",
        "golois.getValidation (input_data, policy, value, end)\n",
        "\n",
        "# Load models\n",
        "h5_files = []\n",
        "for name in os.listdir():\n",
        "  if name[-2:] == 'h5':\n",
        "    h5_files.append(name)\n",
        "\n",
        "# if only one model\n",
        "h5_files = ['model_resnet_Adam_lr1_10-4.h5']\n",
        "for model_filename in h5_files:\n",
        "  model = keras.models.load_model(model_filename)\n",
        "  m_names = model.metrics_names\n",
        "\n",
        "  val = model.evaluate (input_data,\n",
        "                        [policy, value], verbose = 0, batch_size=batch)\n",
        "  print(\"\")\n",
        "  print(\"*******************\")\n",
        "  print(model_filename)\n",
        "  for i, metric in enumerate(m_names):\n",
        "    print(metric, \":\", val[i])\n",
        "  #display(keras.utils.plot_model(model, str(model_name + \".png\"), show_shapes=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMNThL0cfVE5",
        "outputId": "31f22c82-2c4c-4dca-f62a-18e24b0f3832"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getValidation\n",
            "\n",
            "*******************\n",
            "model_resnet_Adam_lr1_10-4.h5\n",
            "loss : 3.718195676803589\n",
            "policy_loss : 3.0275330543518066\n",
            "value_loss : 0.6893633008003235\n",
            "policy_categorical_accuracy : 0.3059000074863434\n",
            "value_mse : 0.11816979944705963\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}